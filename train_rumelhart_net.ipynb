{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Rumelhart and Todd network (1993)\n",
    "\n",
    "### Ethan Blackwood\n",
    "### September 28, 2020\n",
    "\n",
    "**Goal**: Simulate the Rumelhart & Todd connectionist semantic memory network shown in Rogers & McClelland (2008)\n",
    "Figure 1, and replicate the results in Figure 3 regarding the similarity of internal item representations over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import ptree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, build the tree that contains all our inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  ['oak', 'rose', 'robin', 'sunfish', 'pine', 'canary', 'salmon', 'daisy']\n",
      "Relations:  ['is', 'has', 'ISA', 'can']\n",
      "Attributes:  ['flower', 'move', 'branches', 'wings', 'fish', 'tree', 'yellow', 'grow', 'organism', 'scales', 'rose', 'pretty', 'leaves', 'pine', 'animal', 'feathers', 'canary', 'petals', 'big', 'bird', 'bark', 'swim', 'green', 'sing', 'living', 'roots', 'plant', 'gills', 'oak', 'skin', 'red', 'robin', 'sunfish', 'salmon', 'daisy', 'fly']\n",
      "\n",
      "Some examples:\n",
      "x_item shape:  torch.Size([32, 8])\n",
      "x_rel shape:  torch.Size([32, 4])\n",
      "y shape:  torch.Size([32, 36])\n",
      "canary has: wings, feathers, skin\n",
      "salmon ISA: fish, organism, animal, salmon\n",
      "robin has: wings, feathers, skin\n",
      "daisy has: leaves, petals, roots\n"
     ]
    }
   ],
   "source": [
    "# can afford to use doubles for this\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "rumeltree = ptree.from_xml('rumeltree.xml')\n",
    "\n",
    "# Convert to lists so we have a canonical order for items, relations, and attributes.\n",
    "items = list(rumeltree['items'])\n",
    "relations = list(rumeltree['relations'])\n",
    "attributes = list(rumeltree['attributes'])\n",
    "\n",
    "# Now make our inputs and outputs.\n",
    "item_vecs = torch.eye(len(items)).split(1)\n",
    "rel_vecs = torch.eye(len(relations)).split(1)\n",
    "xs = torch.cat([torch.cat((item, rel), dim=1)\n",
    "                  for item in item_vecs for rel in rel_vecs], dim=0)\n",
    "\n",
    "x_item = xs[:, :len(items)]\n",
    "x_rel = xs[:, len(items):]\n",
    "\n",
    "y = torch.zeros((len(xs), len(attributes)))\n",
    "\n",
    "for kI in range(len(items)):\n",
    "    for kR in range(len(relations)):\n",
    "\n",
    "        # get attributes to associate\n",
    "        my_attrs = rumeltree['nodes'][items[kI]].get_related_attributes(relations[kR])\n",
    "        attr_inds = np.isin(attributes, list(my_attrs))\n",
    "        y[kI*len(relations) + kR, attr_inds] = 1\n",
    "\n",
    "print('Items: ', items)\n",
    "print('Relations: ', relations)\n",
    "print('Attributes: ', attributes)\n",
    "print()\n",
    "print('Some examples:')\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "print('x_item shape: ', x_item.shape)\n",
    "print('x_rel shape: ', x_rel.shape)\n",
    "print('y shape: ', y.shape)\n",
    "\n",
    "for k in rng.choice(len(xs), size=4, replace=False):\n",
    "    item_hot = x_item[k].numpy().nonzero()[0]\n",
    "    item = items[item_hot[0]]\n",
    "    rel_hot = x_rel[k].numpy().nonzero()[0]\n",
    "    relation = relations[rel_hot[0]]\n",
    "    \n",
    "    attrs_hot = y[k].numpy().nonzero()[0]\n",
    "    attrs = [attributes[i] for i in attrs_hot]\n",
    "    \n",
    "    print(f'{item} {relation}: {\", \".join(attrs) if len(attrs) > 0 else \"<nothing>\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the network and training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RumelNet(nn.Module):\n",
    "    def __init__(self, n_items, n_relations, n_attributes):\n",
    "        super(RumelNet, self).__init__()\n",
    "        \n",
    "        self.n_items = n_items\n",
    "        self.n_relations = n_relations\n",
    "        self.n_attributes = n_attributes\n",
    "        \n",
    "        rep_size = 8\n",
    "        hidden_size = 15\n",
    "        \n",
    "        # define layers\n",
    "        self.item_to_rep = nn.Linear(n_items, rep_size)\n",
    "        self.rep_to_hidden = nn.Linear(rep_size, hidden_size)\n",
    "        self.rel_to_hidden = nn.Linear(n_relations, hidden_size, bias=False) # only need one hidden layer bias\n",
    "        self.hidden_to_attr = nn.Linear(hidden_size, n_attributes)\n",
    "        \n",
    "        # make weights/biases start small\n",
    "        with torch.no_grad():\n",
    "            for p in self.parameters():\n",
    "                nn.init.normal_(p.data, std=0.01)\n",
    "                #nn.init.uniform_(p.data, a=-0.01, b=0.01)\n",
    "\n",
    "    def forward(self, item, relation):\n",
    "        rep = torch.sigmoid(self.item_to_rep(item))\n",
    "        hidden = torch.sigmoid(self.rep_to_hidden(rep) + self.rel_to_hidden(relation))\n",
    "        attr = torch.sigmoid(self.hidden_to_attr(hidden))\n",
    "        return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(net, optimizer, num_epochs=200, snap_freq=20, batch_size=4, scheduler=None):   \n",
    "    n_snaps = num_epochs // snap_freq\n",
    "    n_items = net.n_items\n",
    "    n_rep = net.item_to_rep.out_features\n",
    "    \n",
    "    # Holds snapshots of input representation layer after probing with each item\n",
    "    rep_snapshots = np.ndarray((n_snaps, n_items, n_rep))\n",
    "    \n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    n_batches = (len(xs)-1) // batch_size + 1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # collect snapshot\n",
    "        if epoch % snap_freq == 0:\n",
    "            k_snap = epoch // snap_freq\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for k_item, item in enumerate(item_vecs):\n",
    "                    act = torch.sigmoid(net.item_to_rep(item))\n",
    "                    rep_snapshots[k_snap, k_item, :] = act\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "\n",
    "        order = rng.permutation(len(xs))\n",
    "        for k_batch in range(n_batches):\n",
    "            # train\n",
    "            batch_inds = order[k_batch*batch_size:(k_batch+1)*batch_size] \n",
    "            \n",
    "            outputs = net(x_item[batch_inds], x_rel[batch_inds])\n",
    "            loss = criterion(outputs, y[batch_inds])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item() * len(batch_inds)\n",
    "                accuracy = torch.mean(((outputs > 0.5).to(torch.double) == y[batch_inds]).to(torch.double))\n",
    "                running_accuracy += accuracy.item() * len(batch_inds)\n",
    "        \n",
    "        if epoch % snap_freq == 0:\n",
    "            print(f'Epoch {epoch} end: mean loss = {running_loss / len(xs):.3f}, mean accuracy = {running_accuracy / len(xs):.3f}')\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    return rep_snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moment of truth, time to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 end: mean loss = 92.102, mean accuracy = 0.860\n",
      "Epoch 1000 end: mean loss = 18.740, mean accuracy = 0.940\n",
      "Epoch 2000 end: mean loss = 17.339, mean accuracy = 0.944\n",
      "Epoch 3000 end: mean loss = 12.986, mean accuracy = 0.959\n",
      "Epoch 4000 end: mean loss = 10.274, mean accuracy = 0.964\n",
      "Epoch 5000 end: mean loss = 8.777, mean accuracy = 0.977\n",
      "Epoch 6000 end: mean loss = 7.012, mean accuracy = 0.983\n",
      "Epoch 7000 end: mean loss = 5.729, mean accuracy = 0.985\n",
      "Epoch 8000 end: mean loss = 4.876, mean accuracy = 0.984\n",
      "Epoch 9000 end: mean loss = 4.374, mean accuracy = 0.985\n",
      "Epoch 10000 end: mean loss = 4.059, mean accuracy = 0.985\n",
      "Epoch 11000 end: mean loss = 3.840, mean accuracy = 0.987\n",
      "Epoch 12000 end: mean loss = 3.678, mean accuracy = 0.989\n",
      "Epoch 13000 end: mean loss = 3.540, mean accuracy = 0.990\n",
      "Epoch 14000 end: mean loss = 3.410, mean accuracy = 0.990\n",
      "Epoch 15000 end: mean loss = 3.292, mean accuracy = 0.990\n",
      "Epoch 16000 end: mean loss = 3.188, mean accuracy = 0.990\n",
      "Epoch 17000 end: mean loss = 3.094, mean accuracy = 0.991\n",
      "Epoch 18000 end: mean loss = 3.010, mean accuracy = 0.992\n",
      "Epoch 19000 end: mean loss = 2.929, mean accuracy = 0.992\n",
      "Epoch 20000 end: mean loss = 2.849, mean accuracy = 0.992\n",
      "Epoch 21000 end: mean loss = 2.768, mean accuracy = 0.992\n",
      "Epoch 22000 end: mean loss = 2.680, mean accuracy = 0.993\n",
      "Epoch 23000 end: mean loss = 2.582, mean accuracy = 0.994\n",
      "Epoch 24000 end: mean loss = 2.456, mean accuracy = 0.994\n",
      "Epoch 25000 end: mean loss = 2.298, mean accuracy = 0.997\n",
      "Epoch 26000 end: mean loss = 2.147, mean accuracy = 0.997\n",
      "Epoch 27000 end: mean loss = 2.020, mean accuracy = 0.997\n",
      "Epoch 28000 end: mean loss = 1.912, mean accuracy = 0.998\n",
      "Epoch 29000 end: mean loss = 1.821, mean accuracy = 0.998\n"
     ]
    }
   ],
   "source": [
    "net = RumelNet(len(items), len(relations), len(attributes))\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.95)\n",
    "\n",
    "rep_snapshots = train_network(net, optimizer, batch_size=4, snap_freq=1000, num_epochs=30000, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d332d4a8d5d4fdab50297d2ff32c078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = hierarchy.linkage(rep_snapshots[-1])\n",
    "plt.figure()\n",
    "hierarchy.dendrogram(z, labels=items)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9611ccf0d75b477298e436a385df6619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test trained net\n",
    "with torch.no_grad():\n",
    "    ind = 5\n",
    "    \n",
    "    item_vec = x_item[ind]\n",
    "    rel_vec = x_rel[ind]\n",
    "\n",
    "    item = items[item_vec.numpy().nonzero()[0].item()]\n",
    "    relation = relations[rel_vec.numpy().nonzero()[0].item()]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 12))\n",
    "    y_test = net(item_vec, rel_vec);\n",
    "    h1 = ax.barh(range(len(attributes)), y_test.squeeze().numpy(),\n",
    "                 align='edge', height=0.4, tick_label=attributes)\n",
    "    h2 = ax.barh(range(len(attributes)), y[ind].squeeze().numpy(),\n",
    "                 align='edge', height=-0.4, tick_label=attributes)\n",
    "    ax.legend([h1, h2], ['Actual', 'Expected'])\n",
    "    ax.set_title(f'{item} {relation}...', size='x-large')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201d77e4ea8542b180d64a775fab021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try making MDS plot from snapshots (Figure 4 in Rogers/McClelland)\n",
    "\n",
    "embedding = MDS(n_components=2)\n",
    "n_snaps, n_items, n_rep = rep_snapshots.shape\n",
    "all_reprs = rep_snapshots.reshape((n_snaps * n_items, n_rep))\n",
    "\n",
    "reprs_embedded = embedding.fit_transform(all_reprs)\n",
    "reprs_embedded = reprs_embedded.reshape((n_snaps, n_items, 2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for kI, col in zip(range(n_items), mcolors.TABLEAU_COLORS):\n",
    "    ax.plot(reprs_embedded[:, kI, 0], reprs_embedded[:, kI, 1], '.-',\n",
    "            label=items[kI], markersize=4, color=col, linewidth=0.5)\n",
    "    \n",
    "for kI, col in zip(range(n_items), mcolors.TABLEAU_COLORS):\n",
    "    ax.plot(reprs_embedded[0, kI, 0], reprs_embedded[0, kI, 1], 'g.',\n",
    "           markersize=14)\n",
    "    ax.plot(reprs_embedded[0, kI, 0], reprs_embedded[0, kI, 1], '.',\n",
    "           markersize=8, color=col)\n",
    "    ax.plot(reprs_embedded[-1, kI, 0], reprs_embedded[-1, kI, 1], 'r.',\n",
    "           markersize=14)\n",
    "    ax.plot(reprs_embedded[-1, kI, 0], reprs_embedded[-1, kI, 1], '.',\n",
    "           markersize=8, color=col)\n",
    "    \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ba98878aaa4427976eef495996a777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same but with PCA\n",
    "\n",
    "embedding = PCA(n_components=2)\n",
    "n_snaps, n_items, n_rep = rep_snapshots.shape\n",
    "all_reprs = rep_snapshots.reshape((n_snaps * n_items, n_rep))\n",
    "\n",
    "reprs_embedded = embedding.fit_transform(all_reprs)\n",
    "reprs_embedded = reprs_embedded.reshape((n_snaps, n_items, 2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for kI, col in zip(range(n_items), mcolors.TABLEAU_COLORS):\n",
    "    ax.plot(reprs_embedded[:, kI, 0], reprs_embedded[:, kI, 1], '.-',\n",
    "            label=items[kI], markersize=4, color=col, linewidth=0.5)\n",
    "    \n",
    "for kI, col in zip(range(n_items), mcolors.TABLEAU_COLORS):\n",
    "    ax.plot(reprs_embedded[0, kI, 0], reprs_embedded[0, kI, 1], 'g.',\n",
    "           markersize=14)\n",
    "    ax.plot(reprs_embedded[0, kI, 0], reprs_embedded[0, kI, 1], '.',\n",
    "           markersize=8, color=col)\n",
    "    ax.plot(reprs_embedded[-1, kI, 0], reprs_embedded[-1, kI, 1], 'r.',\n",
    "           markersize=14)\n",
    "    ax.plot(reprs_embedded[-1, kI, 0], reprs_embedded[-1, kI, 1], '.',\n",
    "           markersize=8, color=col)\n",
    "    \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0d7cc26cba42c481193146c20f5739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# ax.matshow(embedding.components_)\n",
    "with torch.no_grad():\n",
    "    ax.matshow(torch.sigmoid(net.item_to_rep.weight).numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
