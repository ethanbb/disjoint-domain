{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disjoint-domain network\n",
    "\n",
    "### Ethan Blackwood\n",
    "### October 23, 2020\n",
    "\n",
    "**Goal**: Train and analyze the network in Rogers/McClelland 2008 with 4 disjoint domains (Figures R3-R5), which learns to extract the feature of being more or less similar to other items in the same domain, across the 4 domains which have no items, contexts or attributes in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import torch\n",
    "\n",
    "import disjoint_domain as dd\n",
    "import ddnet\n",
    "\n",
    "device, torchfp = dd.init_torch()\n",
    "if device.type == 'cuda':\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    print('Not using CUDA')\n",
    "\n",
    "ctx_per_domain, n_domains, n_items, n_ctx, attrs_per_context = dd.get_net_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Common training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_n_dd_nets(n=36, run_type='dd', snap_report_freq=100, **net_params):\n",
    "\n",
    "    num_epochs = 4000\n",
    "    batch_size = 16\n",
    "    snap_epochs = dd.calc_snap_epochs(snap_report_freq, 'lin', num_epochs)\n",
    "\n",
    "    all_snaps = {'item': [], 'context': []}\n",
    "    all_reports = {'loss': [], 'accuracy': [], 'etg': []}\n",
    "\n",
    "    for i in range(n):\n",
    "        net = ddnet.DisjointDomainNet(ctx_per_domain, attrs_per_context, n_domains,\n",
    "                                      device=device, torchfp=torchfp, **net_params)\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "        #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3000, gamma=0.95)\n",
    "        scheduler = None\n",
    "\n",
    "        print(f'Training Iteration {i+1}')\n",
    "        print('---------------------')\n",
    "        snaps, snap_epochs, reports, report_epochs = net.do_training(\n",
    "            optimizer, num_epochs=num_epochs, batch_size=batch_size, report_freq=snap_report_freq,\n",
    "            snap_freq=snap_report_freq, scheduler=scheduler, do_holdout_testing=True)\n",
    "\n",
    "        for snap_type in ['item', 'context']:\n",
    "            all_snaps[snap_type].append(snaps[snap_type])\n",
    "\n",
    "        for report_type in ['loss', 'accuracy', 'etg']:\n",
    "            all_reports[report_type].append(reports[report_type])\n",
    "\n",
    "        print('')\n",
    "\n",
    "    np.savez(f'data/{run_type}_res_{dt.now():%Y-%m-%d_%H-%M-%S}',\n",
    "             snapshots=all_snaps, snap_freq=snap_report_freq, snap_epochs=snap_epochs,\n",
    "             reports=all_reports, report_freq=snap_report_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original network, with separate item & context streams, with hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 1\n",
      "---------------------\n",
      "Holding out item: D4*\n",
      "Holding out context: A1\n",
      "Epoch    0 end: loss = 215.146, acc = 0.558, epochs to gen. = >2000\n",
      "Epoch  100 end: loss =   7.328, acc = 0.984, epochs to gen. = 990  \n",
      "Epoch  200 end: loss =   4.430, acc = 0.991, epochs to gen. = 43   \n",
      "Epoch  300 end: loss =   4.207, acc = 0.991, epochs to gen. = 42   \n",
      "Epoch  400 end: loss =   4.010, acc = 0.992, epochs to gen. = 29   \n",
      "Epoch  500 end: loss =   3.842, acc = 0.992, epochs to gen. = 25   \n",
      "Epoch  600 end: loss =   3.681, acc = 0.992, epochs to gen. = 24   \n",
      "Epoch  700 end: loss =   3.531, acc = 0.993, epochs to gen. = 32   \n",
      "Epoch  800 end: loss =   3.381, acc = 0.993, epochs to gen. = 70   \n",
      "Epoch  900 end: loss =   3.211, acc = 0.993, epochs to gen. = 23   \n",
      "Epoch 1000 end: loss =   3.084, acc = 0.994, epochs to gen. = 31   \n",
      "Epoch 1100 end: loss =   2.959, acc = 0.994, epochs to gen. = 49   \n",
      "Epoch 1200 end: loss =   2.817, acc = 0.994, epochs to gen. = 17   \n"
     ]
    }
   ],
   "source": [
    "train_n_dd_nets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Network with merged representation layer (items & contexts all go to all rep units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_n_dd_nets(run_type='merged_dd', merged=True)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
